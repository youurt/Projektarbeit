
\RequirePackage[ngerman=ngerman-x-latest]{hyphsubst}
\documentclass[
        ngerman,
        paper=a4,
        numbers=noendperiod,
]{scrreprt}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
% Encoding
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Sprachsupport
\usepackage[ngerman]{babel}
\usepackage{translator}
% Tabellen
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{pdflscape}
\usepackage{multirow}
% Symbole
\usepackage{eurosym}
% Formeln
\usepackage{amsmath, amsthm, amssymb}
% Formelregeln
\DeclareNewTOC[% 
  counterwithin=chapter, 
  indent=0pt,% kein Einzug im Verzeichnis 
  hang=2em,% Einzug für den Text im Verzeichnis 
  name=equation, 
  type=xequation, 
  nonfloat, 
]{loe} 

\AtBeginDocument{% 
  \newcaptionname{ngerman}\xequationname{Formel}% 
  \newcaptionname{ngerman}\listxequationname{Formelverzeichnis}% 
} 
% Pakete
\usepackage{amsthm}
\usepackage{float}
\usepackage{wrapfig}
\usepackage[babel,german=quotes]{csquotes}
\usepackage[square,sort]{natbib}
\usepackage[hyphens]{url}
\usepackage{setspace}
\onehalfspacing
\usepackage[
        pdftex,
        hyperfigures,
        hyperindex,
        bookmarksnumbered,
        linktoc=all,
        pdfborder={0.25 0.25 0.25},
        %pdfborder={0 0 0},
        pdfpagelayout=TwoColumnRight,
]{hyperref}
\usepackage[all]{hypcap}
\usepackage{lmodern}
\usepackage[final,babel]{microtype}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage[printonlyused]{acronym}

\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\fancyhf{}
\fancyhead[RE]{\chaptername~\thechapter}
\fancyhead[LO]{\leftmark}
\fancyhead[LE,RO]{\thepage}

%Quellcodes
%Farben
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
%Listing einfaerben
\usepackage{listings}
\lstset{numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	showstringspaces=false,
	frame=l ,
	xleftmargin=15pt,
	xrightmargin=15pt,
	basicstyle=\ttfamily\scriptsize,
	stepnumber=1,
	keywordstyle=\color{blue},          % keyword style
  	commentstyle=\color{dkgreen},       % comment style
  	stringstyle=\color{mauve}         % string literal style
}
%Sprache Festelegen
\lstset{language=R}

\begin{document}
\begin{titlepage}
    \begin{center}
    \huge \textbf{\textsf{Evaluierung von Paradigmen des Question Answering}} \\
    \vspace{1cm}
    \LARGE\textbf{\textsc{Projektarbeit }}\\
    \vspace{1cm}
    \normalsize
    vorgelegt am: \today \\
    \vspace{2.5cm}
    \large \textbf{Fakultät IV - 
Institut für Wissensbasierte
Systeme und Wissensmanagement, Universität Siegen
}
\linebreak
\linebreak
\begin{figure}[H]
    \centering\includegraphics[width=0.4\linewidth]{images/imageuni.pdf}
    \label{fig:Unilabel}
\end{figure}
    \end{center}
    \vspace{3cm}
    \begin{center}
 \normalsize{
    \begin{tabular}{ll}
    	Eingereicht von: & {Ugur Tigu} \\
    	Studiengang: & Wirtschaftsinformatik, Master of Science (M.Sc.)\\
	Erstprüfer: & Prof. Dr.-Ing. Madjid Fathi \\
	Betreuer: &   Johannes Zenkert\\
    \end{tabular}\\
    }
\end{center}
\end{titlepage}
\setcounter{page}{0}
\pagenumbering{Roman}
\tableofcontents
\clearpage 
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\listoffigures
\clearpage 
\addcontentsline{toc}{chapter}{Tabellenverzeichnis}
\listoftables
\clearpage 
% Kapiteldefinition ohne Nummerierung
\chapter*{Abkürzungsverzeichnis}
 % Abkürzungsverzeichnis soll im Inhaltsverzeichnis erscheinen
\addcontentsline{toc}{chapter}{Abkürzungsverzeichnis} 
\begin{acronym}
% Format der Abkürzungsdefinition: \acro{}[]{}
% {Verweis}[Abkürzung]{ausgeschriebene Abkürzung}

\acro{nlp}[NLP]{Natural Language Processing}
\acro{qa}[QA]{Question Answering}
\acro{ir}[IR]{Information Retrieval}
\acro{pos}[POS]{Part-of-speech}

\end{acronym}
\clearpage 
\addcontentsline{toc}{chapter}{Formelverzeichnis} 
\listofxequations
\clearpage
\setcounter{page}{1}
\pagenumbering{arabic}





\chapter{Einleitung}




\section{Motivation}

\section{Hauptidee der Projektarbeit}

\section{Verwandte Arbeiten}








\chapter{Theoretische Grundlagen}

\section{Question Answering}


\section{Information Retrieval}

\section{Natural Language Processing}


\section{Machine Learning}

\section{Knowledge Graphs}


%start from here -------------------------------------------till 03/05----------------


\chapter{Question Answering}

\section{Einleitung} % 1 page
\section{Die Geschichte des QA} %1 page
\subsection{Einleitung}
Erste Adaptionen von QA Systemen konnten nur mit strukturierten Listen oder Teilen von begrenzten Datenbanksystemen umgehen. Datenbanken über eine bestimmte Domain wurden entwickelt speziell eine Aufgabe zu lösen. Im Prinzip wurden Datenbanken textbasiert oder durch logische Inferenzen zu Wissensdatenbanken zusammengefasst. Die Antwort wurde dabei gefunden, indem das System eine Übereinstimmung im Textabschnitt gefunden hatte oder durch Fakten das Problem lösen konnte.
\subsection{Erste Anwendungen}
Mit \enquote{BASEBALL}  \citep{Green1961Baseball:Question-answerer} wurden Baseball-Spiele analysiert.  Auf die Frage \enquote{Wie haben die Yankees im Juli gespielt?} konnte das QA-System eine Antwort geben. Das QA-System hatte also eine beschränkte, geschlossene Domain. Zunächst wurde eine syntaktische Analyse der Frage ausgeführt. Die Frage wurde dabei in seine einzelnen Elemente zerlegt und es entstanden Teile wie \enquote{Wie?}, \enquote{die Yankees} und \enquote{in Juli}. Da es nur Baseball-Spiele ging, konnte das QA-System direkt mit der semantischen Analyse beginnen. Die semantische Analyse verknüpfte dabei, \enquote{die Yankees} mit der Kondition \enquote{Wie?}. In diesem Fall ist das \enquote{Wie?} die Frage nach dem \enquote{Wie gespielt?}.

Es folgten weitere Anwendungen, wo Enzyklopädien benutzt wurden, um Fragen zu beantworten. Mit \enquote{Protosynthex}\citep{Simmons1964IndexingQuestions} entstand eines der ersten wirklichen QA-Systeme. Um eine Frage zu beantworten, musste diese Systeme zunächst eine Abfrage ausführen. Ähnlich wie bei einer Datenbankabfrage entstand aus den einzelnen Elementen der Frage eine strukturierte Abfrage. Das System gab auf diese strukturierte Abfrage dann bestimmte Antwort Kandidaten. Diese Kandidaten waren die möglichen Antworten. Auf die Frage wurden dann in eine Reihenfolge gebracht. Je ähnlicher die Frage mit der Antwort war, desto höher war der Rang des Kandidaten. Auf die Frage \enquote{Was essen Würmer?} gab das System die korrekte Antwort \enquote{Würmer essen Gras.}, da sowohl die Frage, als auch die Antwort die Abhängigkeit \enquote{essen} beinhalteten. 

Ein weiterer wichtiger Abschnitt bei den ersten QA-Systemen war \enquote{LUNAR} \citep{Woods1978SemanticsAnswering}. Dieses QA-System war eine Brücke zwischen Menschen, die mit natürlicher Sprache kommunizieren und der Chemie, die strukturierte Fakten abbildet. LUNAR beantwortete  Fragen wie \enquote{Gibt es Proben mit 13 Prozent Aluminium?}. 

\subsection{Was kann man aus den Fehlern lernen?}
Die ersten QA-Systeme waren im Grunde wissensbasierte Systeme. Mit dem Fortschritt des Internets kamen aber immer mehr IR-basierte QA-Systeme in den Vordergrund und erst später kam die Kombination dieser beiden Paradigmen, die hybriden Systeme, welche sich noch in dem Beginn ihrer Entwicklung befinden. 

Aus den ersten Implementierungen der QA-Systeme können wir aber lernen, indem wir nicht dieselben Fehler begehen wie diese Systeme. In den 70er Jahren gab es noch sehr wenig Daten, und QA-Systeme leben von Daten. Den wirklichen Durchbruch haben QA-Systeme erst Mitte der 2000'er erhalten. Große Mengen an Daten und ML-Algorithmen, welche diese Daten umwandeln und beherrschen sind der Grund. Es ist nicht ausreichend, nur eine Quelle zu haben, um die Komplexität zu beherrschen. Ein Wort kann in der natürlichen Sprache mehrere Bedeutungen haben. Außerdem ist eine reine Regelbasierte Behandlung der Frage nicht ausreichend.




\section{Aktuelle Entwicklungen im Question Answering} % 1 page

\enquote{Wolfram|Alpha is not a search engine.} \citep{WolframAlpha} Weil die Menschen mehr als eine Suchmaschine gebraucht haben und immer mehr dem Computer Fragen stellten entstanden zunächst Projekte wie Wolfram|Alpha entstanden. Herkömmliche Suchmaschinen arbeiten unter der Annahme, dass die bestimmte Webseiten wonach der Nutzer gesucht hat, die gewünschten Informationen enthalten. Anders bei Wolfram|Alpha wo durch die Suche. Wolfram|Alpha bezeichnet sich selbst als \enquote{Wissensmaschine}. Sie generiert die Antwort, indem sie mit der eigenen internen Wissensbasis arbeitet und nicht nur einen Index wiedergibt. Als zunächst Wolfram|Alpha veröffentlicht wurde, war der Hype sehr groß. Es sollte den von Google dominierten Markt für Suchmaschinen revolutionieren, doch Wolfram|Alpha ist kein Ersatz für herkömmliche Suchmaschinen.

2011 gelang es IBM Watson das Jeopardy! Fernsehprgramm zu gewinnen \citep{Markoff2011ComputerNot}. IBM musst mit Watson gegen Menschen antreten und in natürlicher Sprache gestellte Quizfragen beantworten. Der Computer hatte dabei schnell und prezise aus einer sehr großen Anzahl von Antwortmöglichkeiten, die richtige Antwort auszuwählen. Dieses war eine Demonstration von IBM, wie fortgeschritten die Technik angekommen ist.

Die Entwicklung im Bereich QA ging weiter und auch Google hatte in diesem Bereich eine neue Möglichkeit entdeckt, das QA in die herrkömmliche Suche zu integrieren. Im Mai 2012 hat Google das sogenannte \enquote{Knowledge Graph} eingeführt. Ein Wissensgraph, das reale Entitäten und ihre Beziehungen zueinander verknüpft. Zu den Objekten gehören z.B.: Sehenswürdigkeiten, Prominente, Städte, Sportmannschaften, Gebäude, Filme, Himmelsobjekte, Kunstwerke und mehr. Das Diagramm verbessert die Google-Suche auf drei Arten: die Auflösung von Mehrdeutigkeiten bei Suchanfragen, die Zusammenfassung der wichtigsten Fakten und die explorative Suche \citep{SteinerAddingGraph}.











































\chapter{Question Answering mit Wissensbasis}
\chapter{Question Answering mit Web}
Eine allgemeine Systemarchitektur ist bei der Vielzahl an Paradigmen des QA nicht einfach aufzubauen. Da die ersten QA-Systeme wissensbasierte und IR-basierte Systeme sind, sind diese beiden Systeme auch die Grundlage für die Beschreibung einer allgemeinen Systemarchitektur als geeignete Kandidaten auszuweisen. 

Im Folgenden werden IR-basierte QA als Grundlage ausgewählt. Dieses hat den Zweck, um möglichst alle Komponenten der QA-Systeme abzubilden. IR-basierte QA-Systeme demonstrieren die Umwandlung von Informationen und unstrukturierten Texten, besser als wissensbasierte QA-Systeme, wo eine Abfrage einer Wissensdatenbank erfolgt. Die meisten QA-Systeme beinhalten 3 Komponenten. Diese Komponenten sind 
\begin{itemize}
\item Frage verstehen
\item Fakten extrahieren 
\item Antwort generieren
\end{itemize}




\begin{figure}[H]
    \centering\includegraphics[width=1.0\linewidth]{images/image1.png}
    \caption[Systemarchitektur]{Systemarchitektur, in Anlehnung an \cite []{eff70}}
    \label{fig:diagram1}
\end{figure}





\subsection{Fragebearbeitung}

Im ersten Modul eines QA-Systems geht es darum, die gestellte Frage zu verstehen. Zunächst muss die in natürlicher Sprache gestellten Frage in eine Abfrage umgewandelt werden, welches ein Computer versteht. Außerdem wird in diesem Modul der Typ der gestellten Frage festgelegt um die Auswahl der Antwortkandidaten, welches im letzten Modul eines QA-Systems stattfindet, zu begrenzen.

\subsubsection{Abfrageformulierung}
Zunächst muss die gestellte Frage in eine Abfrage übersetzt werden, welches der Computer verstehen kann. Bei einer Suchmaschine etwa, wird die Frage in natürlicher Sprache gestellt, jedoch muss der Computer im Hintergrund diese Abfrage in eine Datenbankabfrage umwandeln. 
\textbf{LIN 2007} zeigt wie man mittels  \enquote{Query Reformulation} die gestellte Frage reformuliert, also nicht mehr als Frage, sondern als Aussage wiedergibt. Dabei werden vordefinierte Regeln verwendet. Dieses ist nützlich, denn Textausschnitte aus dem Web können unterschiedlich formuliert sein.

\subsubsection{Antworttypen}

Durch Named Entitiy Recognition ist es möglich, die gestellte Frage nach seinem Typ zu kategorisieren. Eine \enquote{Wer-Frage} wird dabei mit Person verknüpft eine \enquote{Wo-Frage} mit dem Ort. Diese Klassifizierung ermöglicht dem System eine Vorselektion durchzuführen. 

Eine \enquote{Taxonomie} von Antworttypen kann aus dem WordNet, wie in den Beispielen \textbf{HARBAYAIN, PASCA}, gebildet werden.

Im Beispiel von \textbf{Li and Roth 2005} sieht man, wie solche Taxonomien selbst gemacht werden können, also ohne WordNet. Die Granularität dieser Taxonomien kann dabei selbst bestimmt werden. Die Entität PERSON kann dabei viel tiefer behandelt werden, also PERSON:GRUPPE. 


\subsection{Abrufen von Dokumenten und Passagen}
Die aus der Fragenbearbeitungsphase erzeugte IR-Abfrage wird an eine IR-Engine gesendet.
Dies führt zu einer Reihe von Dokumenten, die nach ihrer Relevanz für die Abfrage geordnet sind. Da die meisten Methoden zum Extrahieren von Antworten für kleinere Bereiche wie Absätze ausgelegt sind, unterteilen QA-Systeme als Nächstes die obersten n Dokumente in kleinere Passagen wie z.B. Abschnitte, Absätze oder Sätze. 


Die einfachste Form des Passagen Retrievals besteht darin, jede Passage zur Stufe der Antwortextraktion weiterzuleiten. Eine komplexere Variante besteht darin, die Passagen zu filtern, indem eine benannte Entität oder eine Antworttypklassifizierung für die abgerufenen Passagen ausgeführt wird, wobei Passagen verworfen werden, die nicht den Antworttyp der Frage enthalten. Es ist auch möglich, überwachtes Lernen zu verwenden, um die verbleibenden Passagen mithilfe von Funktionen wie:

\begin{itemize}
\item Die Anzahl der benannten Entitäten des richtigen Typs in der Passage
\item Die Anzahl der Frage-Schlüsselwörter in der Passage 
\item Die längste exakte Folge von Frage-Schlüsselwörtern, die in der Passage vorkommt
\item Der Rang des Dokuments, aus dem die Passage extrahiert wurde
\item Die Nähe von die Schlüsselwörter aus der ursprünglichen Abfrage untereinander (Pasca 2003, Monz 2004).
\item Die Anzahl der n-Gramm, die sich zwischen der Passage und der Frage überlappen (Brill et al., 2002).
\end{itemize}

\subsection{Antwortextraktion}
Die letzte Phase der Beantwortung von Fragen besteht darin, eine bestimmte Antwort aus der Passage zu extrahieren, z. B. auf eine Frage wie „Wie hoch ist der Berg? Everest?" die Höhenangabe zu geben. Diese Aufgabe wird üblicherweise durch Beschriftung modelliert. 
Ein einfacher Algorithmus für die Antwortextraktion besteht darin, einen Entitäts-Tagger in der Kandidatenpassage auszuführen und die passende Passage zurückzugeben, die den richtigen Antworttyp enthält. 
In den folgenden Beispielen würden die unterstrichenen benannten Entitäten aus den Passagen als Antwort auf die Fragen HUMAN und DISTANCE-QUANTITY extrahiert:

\newtheorem{example}{Beispiel}

\begin{example}
\enquote{Wer ist der indische Premierminister?} - \textbf{Manmohan Singh}, Premierminister von Indien, hatte den linken Führern gesagt, dass das Abkommen nicht neu verhandelt werden würde.

\end{example}
\begin{example}
\enquote{Wie hoch ist der Berg Everest?} - Die offizielle Höhe des Mount Everest beträgt \textbf{29029 Fuß}.
\end{example}

Leider sind die Antworten auf viele Fragen, wie z. B. DEFINITION-Fragen, in der Regel nicht von einem bestimmten benannten Entitätentyp. Aus diesem Grund verwendet die moderne Arbeit zur Antwortextraktion komplexere Algorithmen, die im Allgemeinen auf überwachtem Lernen basieren. Im nächsten Abschnitt wird ein einfacher merkmalsbasierter Klassifikator vorgestellt. Anschließend wenden wir uns modernen neuronalen Algorithmen zu.



\chapter{Hybrides Question Answering}

\chapter{Question Answering mit BERT }
\chapter{Evaluationsmethoden}




















%end here -------------------------------------------till 03/05---------------- 



\chapter{Methodik}
\section{Analyseverfahren}
\chapter{Ergebnis}
\section{Interpretation der Ergebnisse}
\chapter{Fazit}
\appendix 
\chapter{Anhang}
\label{chapter:Anhang}%


\clearpage
        \phantomsection % damit das pdf bookmark an die richtige Stelle zeigt
        \pdfbookmark{Literaturverzeichnis}{bibliography}
        
        % zeigt immer alle definierten Quellen an, auch wenn diese nicht verwendet werden
        %\nocite{*}
        \bibliographystyle{alpha}
        \addcontentsline{toc}{chapter}{Literaturverzeichnis}
        \bibliography{literatur}




\chapter*{Erklärung}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe, insbesondere keine anderen als die angegebenen Informationen aus dem Internet. Diejenigen Paragraphen der für mich gültigen Prüfungsordnung, welche etwaige Betrugsversuche betreffen, habe ich zur Kenntnis genommen. Der Speicherung meiner Master-Arbeit zum Zweck der Plagiatsprüfung stimme ich zu. Ich versichere, dass die elektronische Version mit der gedruckten Version inhaltlich übereinstimmt.\newline
\linebreak
\linebreak
\linebreak
Bielefeld, den 01.04.2020\newline
(Ort) (Datum)\newline
\linebreak
\linebreak
\linebreak
..................................\newline
(Unterschrift)
\end{document}